""" Toy ELIS SLR Agent runner.  Purpose ------- Produce minimal, schema-aligned artefacts for A/B/C so CI can smoke-test the pipeline. Files are written under `json_jsonl/` as pretty-printed JSON arrays.  Compatibility ------------- Matches minimal schemas: - schemas/ELIS_Appendix_A_Search.schema.json - schemas/ELIS_Appendix_B_Screening.schema.json - schemas/ELIS_Appendix_C_Extraction.schema.json """  import json from datetime import datetime, timezone from pathlib import Path   # --------------------------------------------------------------------------- # # Artefact locations (tests may override these module-level globals) # --------------------------------------------------------------------------- #  ART_DIR = Path("json_jsonl") A_FILE = ART_DIR / "ELIS_Appendix_A_Search_rows.json" B_FILE = ART_DIR / "ELIS_Appendix_B_Screening_rows.json" C_FILE = ART_DIR / "ELIS_Appendix_C_Extraction_rows.json"   # --------------------------------------------------------------------------- # # Helpers # --------------------------------------------------------------------------- #  def _now() -> str:     """Return current UTC timestamp in ISO-8601 with trailing 'Z'."""     return datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")   def _write_json(path: Path, data) -> None:     """Write `data` to `path` as deterministic UTF-8 JSON."""     path.parent.mkdir(parents=True, exist_ok=True)     with path.open("w", encoding="utf-8") as f:         json.dump(data, f, ensure_ascii=False, indent=2)   # --------------------------------------------------------------------------- # # Core run # --------------------------------------------------------------------------- #  def run():     """     Emit minimal A/B/C rows and persist them to disk.      Returns     -------     dict: keys 'a', 'b', 'c' with the lists that were written.     """     # Appendix A — Search     a_rows = [         {             "id": "A-0001",             "search_query": "electronic voting integrity",             "source": "DemoEngine",             "executed_at": _now(),             "notes": "toy run",         }     ]      # Appendix B — Screening (both included and excluded examples)     b_rows = [         {             "id": "B-0001",             "source_id": "A-0001",             "title": "Pilot study on electronic voting",             "decision": "included",             "decided_at": _now(),         },         {             "id": "B-0002",             "source_id": "A-0001",             "title": "Blog post without methodology",             "decision": "excluded",             "reason": "Not peer-reviewed / out of scope",             "decided_at": _now(),         },     ]      # Appendix C — Extraction (only for included items)     c_rows = [         {             "id": "C-0001",             "screening_id": "B-0001",             "key_findings": "Example extraction placeholder.",             "extracted_at": _now(),             "notes": "toy run",         }     ]      # Persist     _write_json(A_FILE, a_rows)     _write_json(B_FILE, b_rows)     _write_json(C_FILE, c_rows)      return {"a": a_rows, "b": b_rows, "c": c_rows}   # --------------------------------------------------------------------------- # # CLI entrypoint # --------------------------------------------------------------------------- #  if __name__ == "__main__":     # Allow `python scripts/agent.py` for ad-hoc runs.     out = run()     print(         json.dumps(             {                 "written": {                     "A_FILE": str(A_FILE),                     "B_FILE": str(B_FILE),                     "C_FILE": str(C_FILE),                 },                 "counts": {k: len(v) for k, v in out.items()},             },             ensure_ascii=False,             indent=2,         )     )
