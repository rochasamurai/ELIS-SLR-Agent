""" ELIS SLR Agent — toy runner (Step A/B/C)  Purpose ------- Produce minimal, schema-aligned artefacts for the ELIS SLR Agent: - Appendix A (Search) rows - Appendix B (Screening) rows — includes `decision` and, when excluded, a   `reason` - Appendix C (Extraction) rows  Design notes ------------ - Files are written under `json_jsonl/` as pretty-printed JSON arrays. - Timestamps use ISO-8601 in UTC with a trailing 'Z'. - This is a **toy** implementation for CI smoke tests and demonstrations.  Schema compatibility -------------------- Matches minimal schemas in:   - schemas/ELIS_Appendix_A_Search.schema.json   - schemas/ELIS_Appendix_B_Screening.schema.json   - schemas/ELIS_Appendix_C_Extraction.schema.json  Keep `additionalProperties: false` in mind when editing field names. """  from __future__ import annotations  import json from datetime import datetime, timezone from pathlib import Path from typing import Any  # ---------- Types and artefact locations -------------------------------------  # Simple alias for rows Row = dict[str, Any]  # Directory for artefacts (tests may override these at runtime) ART_DIR: Path = Path("json_jsonl") A_FILE: Path = ART_DIR / "ELIS_Appendix_A_Search_rows.json" B_FILE: Path = ART_DIR / "ELIS_Appendix_B_Screening_rows.json" C_FILE: Path = ART_DIR / "ELIS_Appendix_C_Extraction_rows.json"   # ---------- Utilities ---------------------------------------------------------   def _now() -> str:     """     Return current UTC time as ISO-8601 with trailing 'Z'.      Example: '2025-09-30T12:34:56.123456Z'     """     return datetime.now(timezone.utc).isoformat().replace("+00:00", "Z")   def _write_json(path: Path, data: Any) -> None:     """     Write JSON to `path` using UTF-8 and deterministic formatting.     Creates parent directories if needed.     """     path.parent.mkdir(parents=True, exist_ok=True)     with path.open("w", encoding="utf-8") as f:         json.dump(data, f, ensure_ascii=False, indent=2)   # ---------- Core run ----------------------------------------------------------   def run() -> dict[str, list[Row]]:     """     Execute a toy run that emits A/B/C rows and persists them to disk.      Returns     -------     dict         Keys 'a', 'b', 'c' mapping to the in-memory lists written to disk.     """     # Appendix A — Search (minimal single row)     a_rows: list[Row] = [         {             "id": "A-0001",             "search_query": "electronic voting integrity",             "source": "DemoEngine",             "executed_at": _now(),             "notes": "toy run",         }     ]      # Appendix B — Screening     # Includes both 'included' and 'excluded' examples. When excluded, a     # 'reason' is required by schema.     b_rows: list[Row] = [         {             "id": "B-0001",             "source_id": "A-0001",  # references Appendix A 'id'             "title": "Pilot study on electronic voting",             "decision": "included",             "decided_at": _now(),         },         {             "id": "B-0002",             "source_id": "A-0001",             "title": "Blog post without methodology",             "decision": "excluded",             "reason": "Not peer-reviewed / out of scope",             "decided_at": _now(),         },     ]      # Appendix C — Extraction (for included items)     c_rows: list[Row] = [         {             "id": "C-0001",             "screening_id": "B-0001",  # references Appendix B 'id'             "key_findings": "Example extraction placeholder.",             "extracted_at": _now(),             "notes": "toy run",         }     ]      # Persist artefacts     _write_json(A_FILE, a_rows)     _write_json(B_FILE, b_rows)     _write_json(C_FILE, c_rows)      return {"a": a_rows, "b": b_rows, "c": c_rows}   # ---------- Script entrypoint -------------------------------------------------   if __name__ == "__main__":     # Allow running locally: `python scripts/agent.py`     result = run()     print(         json.dumps(             {                 "written": {                     "A_FILE": str(A_FILE),                     "B_FILE": str(B_FILE),                     "C_FILE": str(C_FILE),                 },                 "counts": {key: len(val) for key, val in result.items()},             },             ensure_ascii=False,             indent=2,         )     )
