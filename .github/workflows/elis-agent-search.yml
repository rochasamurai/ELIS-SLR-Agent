name: ELIS - Agent Search (Appendix A)
# =============================================================================
# Purpose
#   Run Appendix A (Search) using protocol-aligned queries, write the canonical
#   JSON artefact (A), and optionally open/refresh a PR with the changes.
#
# This update
#   - Maps newly created repo secrets to adapter-friendly env names:
#       * IEEE_EXPLORE_API_KEY        -> IEEE_API_KEY
#       * SCOPUS_API_KEY              -> SCOPUS_API_KEY
#       * WEB_OF_SCIENCE_API_KEY      -> WOS_API_KEY
#   - Adds real Scopus institutional harvest step using scopus_harvest.py
#   - Leaves all other behaviour unchanged (safe).
#   - Adds production hardening: timeouts, caching, validation, error handling
#
# Usage
#   - Manual trigger (workflow_dispatch) with runtime knobs.
#   - Uploads artefact (14d retention).
#   - Commits on a dedicated branch and optionally opens/refreshes a PR.
# =============================================================================

on:
  workflow_dispatch:
    inputs:
      base_branch:
        description: "Base branch to PR into"
        required: false
        default: "main"
      write_branch:
        description: "Work branch to write artefacts (auto-suffixed if exists)"
        required: false
        default: "ci/agent-search-autopr"
      open_pr:
        description: "Open/refresh PR write_branch -> base_branch"
        required: false
        default: "true"
      cap_per_source:
        description: "Cap per source per topic"
        required: false
        default: "100"
      job_result_cap:
        description: "Hard cap on total results"
        required: false
        default: "1000"
      dry_run:
        description: "Preview only (no write/commit/PR)"
        type: boolean
        required: false
        default: true

permissions:
  contents: write
  pull-requests: write

concurrency:
  group: agent-search-${{ github.ref }}
  cancel-in-progress: false

jobs:
  search-a:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    defaults:
      run:
        shell: bash

    steps:
      - name: Mint installation token (GitHub App)
        id: app
        uses: actions/create-github-app-token@v1
        with:
          app-id: ${{ secrets.ELIS_APP_ID }}
          private-key: ${{ secrets.ELIS_APP_PRIVATE_KEY }}

      - name: Checkout repository (App token)
        uses: actions/checkout@v4
        with:
          token: ${{ steps.app.outputs.token }}
          fetch-depth: 0

      - name: Configure Git identity
        run: |
          git config user.name  "elis-bot"
          git config user.email "elis-bot@users.noreply.github.com"

      - name: Resolve run-time knobs
        id: knobs
        run: |
          set -euo pipefail

          BASE="${{ github.event.inputs.base_branch || 'main' }}"
          HEAD="${{ github.event.inputs.write_branch || 'ci/agent-search-autopr' }}"
          OPEN_PR="${{ github.event.inputs.open_pr || 'true' }}"
          CAP_PER_SOURCE="${{ github.event.inputs.cap_per_source || '100' }}"
          JOB_RESULT_CAP="${{ github.event.inputs.job_result_cap || '1000' }}"
          DRY_RUN="${{ github.event.inputs.dry_run || 'false' }}"

          echo "base=$BASE" >> "$GITHUB_OUTPUT"
          echo "head=$HEAD" >> "$GITHUB_OUTPUT"
          echo "open_pr=$OPEN_PR" >> "$GITHUB_OUTPUT"
          echo "cap_per_source=$CAP_PER_SOURCE" >> "$GITHUB_OUTPUT"
          echo "job_result_cap=$JOB_RESULT_CAP" >> "$GITHUB_OUTPUT"
          echo "dry_run=$DRY_RUN" >> "$GITHUB_OUTPUT"

      - name: Prepare write branch (create or fast-forward)
        run: |
          set -eux
          BASE="${{ steps.knobs.outputs.base }}"
          HEAD="${{ steps.knobs.outputs.head }}"
          git fetch origin --prune
          if git ls-remote --exit-code --heads origin "$HEAD" >/dev/null 2>&1; then
            git checkout -B "$HEAD" "origin/$HEAD"
            (git merge --ff-only "origin/$BASE" && echo "FF merged base") || true
          else
            git checkout -B "$HEAD" "origin/$BASE"
            git push -u origin "$HEAD"
          fi

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install runtime deps (pinned)
        run: |
          python -m pip install --upgrade pip
          pip install "requests==2.32.3" "PyYAML==6.0.2"

      - name: Patch search config from UI inputs
        env:
          CAP_PER_SOURCE:  ${{ steps.knobs.outputs.cap_per_source }}
          JOB_RESULT_CAP:  ${{ steps.knobs.outputs.job_result_cap }}
        run: |
          python - <<'PY'
          import yaml, sys, pathlib, os
          src = pathlib.Path("config/elis_search_queries.yml")
          if not src.exists():
              print("Config file not found: config/elis_search_queries.yml", file=sys.stderr)
              sys.exit(2)
          with src.open("r", encoding="utf-8") as f:
              cfg = yaml.safe_load(f) or {}
          g = cfg.setdefault("global", {})
          def to_int(v, default):
              try:
                  return int(str(v).strip())
              except Exception:
                  return default
          g["max_results_per_source"] = to_int(os.environ.get("CAP_PER_SOURCE", "100"), 100)
          g["job_result_cap"] = to_int(os.environ.get("JOB_RESULT_CAP", "1000"), 1000)
          out = pathlib.Path("/tmp/elis_config.yml")
          out.write_text(yaml.safe_dump(cfg, sort_keys=False, allow_unicode=True), encoding="utf-8")
          print(f"Wrote patched config to {out}")
          PY

      - name: Run Appendix A (Search)
        env:
          ELIS_CONTACT: "elis@samurai.com.br"
          ELIS_HTTP_SLEEP_S: "1.0"
          SEMANTIC_SCHOLAR_API_KEY: ${{ secrets.SEMANTIC_SCHOLAR_API_KEY }}
          IEEE_API_KEY: ${{ secrets.IEEE_EXPLORE_API_KEY }}
          SCOPUS_API_KEY: ${{ secrets.SCOPUS_API_KEY }}
          WOS_API_KEY: ${{ secrets.WEB_OF_SCIENCE_API_KEY }}
        run: |
          set -eux
          DRY="${{ steps.knobs.outputs.dry_run }}"
          if [ "$DRY" = "true" ]; then
            python scripts/elis/search_mvp.py --config /tmp/elis_config.yml --dry-run
          else
            python scripts/elis/search_mvp.py --config /tmp/elis_config.yml
          fi

      - name: Harvest Scopus Institutional API
        if: ${{ steps.knobs.outputs.dry_run != 'true' }}
        run: |
          # --------------------------------------------
          # Run Scopus Institutional Harvest
          # Requires valid API key and institution token
          # --------------------------------------------
          set -eux
          export SCOPUS_API_KEY="${{ secrets.SCOPUS_API_KEY }}"
          export SCOPUS_INST_TOKEN="${{ secrets.SCOPUS_INST_TOKEN }}"
          
          if [ ! -f scripts/scopus_harvest.py ]; then
            echo "WARNING: scripts/scopus_harvest.py not found, skipping harvest"
            exit 0
          fi
          
          python scripts/scopus_harvest.py

      - name: Validate Appendix A artifact
        if: ${{ steps.knobs.outputs.dry_run != 'true' }}
        run: |
          set -eux
          ARTIFACT="json_jsonl/ELIS_Appendix_A_Search_rows.json"
          
          # Check file exists
          if [ ! -f "$ARTIFACT" ]; then
            echo "ERROR: Artifact not found at $ARTIFACT"
            exit 1
          fi
          
          # Validate JSON syntax
          if ! python -m json.tool "$ARTIFACT" > /dev/null 2>&1; then
            echo "ERROR: Invalid JSON in $ARTIFACT"
            exit 1
          fi
          
          # Optionally validate against schema (if validator exists)
          if [ -f scripts/validate_json.py ]; then
            python scripts/validate_json.py "$ARTIFACT" || echo "WARNING: Schema validation failed"
          fi
          
          echo "Artifact validation passed"

      - name: Upload artefact (Appendix A JSON)
        if: ${{ steps.knobs.outputs.dry_run != 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: elis-agent-appendix-a
          path: json_jsonl/ELIS_Appendix_A_Search_rows.json
          retention-days: 14

      - name: Commit Appendix A
        if: ${{ steps.knobs.outputs.dry_run != 'true' }}
        run: |
          set -eux
          git add -N json_jsonl/ELIS_Appendix_A_Search_rows.json || true
          if git diff --name-only --exit-code -- json_jsonl/ELIS_Appendix_A_Search_rows.json; then
            echo "No artefact diffs; skipping commit/push/PR."
            echo "skip_pr=true" >> "$GITHUB_ENV"
            exit 0
          fi
          git add json_jsonl/ELIS_Appendix_A_Search_rows.json
          git commit -m "feat(search): update Appendix A results"

      - name: Force remote to App-token URL
        if: "${{ env.skip_pr != 'true' && steps.knobs.outputs.dry_run != 'true' }}"
        run: |
          set -eux
          git remote set-url origin "https://x-access-token:${{ steps.app.outputs.token }}@github.com/${{ github.repository }}"

      - name: Push work branch
        if: ${{ env.skip_pr != 'true' && steps.knobs.outputs.dry_run != 'true' }}
        run: |
          set -eux
          HEAD="${{ steps.knobs.outputs.head }}"
          git push --force-with-lease origin HEAD:"$HEAD"

      - name: Compare base..head & open/refresh PR
        if: ${{ env.skip_pr != 'true' && steps.knobs.outputs.dry_run != 'true' && steps.knobs.outputs.open_pr == 'true' }}
        uses: actions/github-script@v7
        with:
          github-token: ${{ steps.app.outputs.token }}
          script: |
            const owner = context.repo.owner;
            const repo  = context.repo.repo;
            const base  = "${{ steps.knobs.outputs.base }}";
            const head  = "${{ steps.knobs.outputs.head }}";

            try {
              // Compare commits
              const cmp = await github.rest.repos.compareCommitsWithBasehead({
                owner, 
                repo, 
                basehead: `${base}...${head}`,
              });
              
              const hasDiff = (cmp.data.ahead_by > 0) || ((cmp.data.files || []).length > 0);
              
              if (!hasDiff) { 
                core.info("No diff detected; no PR needed."); 
                return; 
              }

              // Check for existing open PRs
              const { data: openPRs } = await github.rest.pulls.list({
                owner, 
                repo, 
                state: 'open', 
                base, 
                head: `${owner}:${head}`,
              });

              if (openPRs.length > 0) {
                core.info(`PR already exists: #${openPRs[0].number}`);
                core.info(`URL: ${openPRs[0].html_url}`);
              } else {
                // Create new PR
                const { data: pr } = await github.rest.pulls.create({
                  owner, 
                  repo, 
                  base, 
                  head,
                  title: "feat(search): update Appendix A results",

body: [
                    '## Automated ELIS Agent Search Run',
                    '',
                    '**Branch:** ' + head,
                    '**Base:** ' + base,
                    '**Triggered by:** @${{ github.actor }}',
                    '**Run:** [#${{ github.run_number }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})',
                    '',
                    '### Changes',
                    '- Updated Appendix A search results',
                    `- Cap per source: ${{ steps.knobs.outputs.cap_per_source }}`,
                    `- Job result cap: ${{ steps.knobs.outputs.job_result_cap }}`,
                    '',
                    '---',
                    '_This PR was automatically created by the ELIS Agent Search workflow._'
                  ].join('\n'),
                
                core.info(`Created PR #${pr.number}`);
                core.info(`URL: ${pr.html_url}`);
              }
            } catch (error) {
              core.setFailed(`Failed to create/check PR: ${error.message}`);
              throw error;
            }

      - name: Job summary
        if: always()
        run: |
          echo "# ELIS Agent Search Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Configuration" >> $GITHUB_STEP_SUMMARY
          echo "- **Base Branch:** \`${{ steps.knobs.outputs.base }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Work Branch:** \`${{ steps.knobs.outputs.head }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Dry Run:** ${{ steps.knobs.outputs.dry_run }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Cap per Source:** ${{ steps.knobs.outputs.cap_per_source }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Job Result Cap:** ${{ steps.knobs.outputs.job_result_cap }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Open PR:** ${{ steps.knobs.outputs.open_pr }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Status" >> $GITHUB_STEP_SUMMARY
          if [ "${{ job.status }}" = "success" ]; then
            echo "✅ Workflow completed successfully" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ Workflow failed" >> $GITHUB_STEP_SUMMARY
          fi
