name: ELIS - Imports Convert
# =============================================================================
# Purpose
#   Convert manual exports from external databases (e.g. Scopus, WoS, IEEE)
#   into the canonical Appendix A JSON format used by ELIS SLR Agent.
#   The job runs a small Python converter and:
#     - writes json_jsonl/ELIS_Appendix_A_Search_rows.json in the workspace
#     - uploads it as a short-lived artifact for download / PR review.
#
# Notes
#   - This workflow does NOT commit to the repository; reviewers should
#     download the artifact and update the JSON file via a PR (or we add
#     an auto-PR mode in a later iteration).
#   - Only Scopus CSV is supported in this MVP (provider = scopus_csv).
# =============================================================================

on:
  workflow_dispatch:
    inputs:
      provider:
        description: "Export provider/format (currently: scopus_csv)"
        type: choice
        required: true
        default: scopus_csv
        options:
          - scopus_csv
      csv_path:
        description: "Path to the export file under the repo (e.g., imports/scopus_export.csv)"
        type: string
        required: true
        default: "imports/scopus_export.csv"
      topic_id:
        description: "Topic id for provenance (e.g., integrity_auditability_core)"
        type: string
        required: true
        default: "scopus_ui_manual"
      search_string:
        description: "Exact search string used in the provider UI (optional, for provenance)"
        type: string
        required: false
        default: ""
      year_from:
        description: "Lower bound year used in the search (for metadata only)"
        type: number
        required: true
        default: 1990
      year_to:
        description: "Upper bound year used in the search (for metadata only)"
        type: number
        required: true
        default: 2025
      languages:
        description: "Comma-separated list of languages (for metadata only)"
        type: string
        required: true
        default: "en,fr,es,pt"

permissions:
  contents: read

concurrency:
  group: imports-convert-${{ github.ref }}
  cancel-in-progress: true

jobs:
  convert:
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install converter dependencies
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install "pandas==2.2.2" "pyyaml==6.0.2"

      # ------------------------------------------------------------------
      # Resolve inputs safely (no shell injection) and run the converter
      # ------------------------------------------------------------------
      - name: Convert export to Appendix A JSON
        id: convert
        env:
          PROVIDER:      ${{ inputs.provider }}
          CSV_PATH:      ${{ inputs.csv_path }}
          TOPIC_ID:      ${{ inputs.topic_id }}
          SEARCH_STRING: ${{ inputs.search_string }}
          YEAR_FROM:     ${{ inputs.year_from }}
          YEAR_TO:       ${{ inputs.year_to }}
          LANGUAGES:     ${{ inputs.languages }}
        run: |
          set -euo pipefail

          # Build argument list in an array to keep quoting safe
          args=( --provider "$PROVIDER" --csv "$CSV_PATH" --query-topic "$TOPIC_ID" --year-from "$YEAR_FROM" --year-to "$YEAR_TO" --languages "$LANGUAGES" )

          if [ -n "${SEARCH_STRING:-}" ]; then
            args+=( --query-string "$SEARCH_STRING" )
          fi

          python scripts/elis/imports_to_appendix_a.py "${args[@]}"

      # ------------------------------------------------------------------
      # Generate a human-friendly Step Summary by reading the JSON _meta
      # ------------------------------------------------------------------
      - name: Imports → Appendix A summary
        if: ${{ always() }}
        run: |
          set -euo pipefail
          python - << 'PY'
          import json
          from pathlib import Path
          import os

          summary_path = Path("json_jsonl/ELIS_Appendix_A_Search_rows.json")
          if not summary_path.is_file():
            print("No Appendix A JSON found; skipping summary.")
            raise SystemExit(0)

          data = json.loads(summary_path.read_text(encoding="utf-8"))
          if not data:
            print("Empty JSON payload; skipping summary.")
            raise SystemExit(0)

          meta = data[0] if isinstance(data[0], dict) else {}
          summary = meta.get("summary", {})
          total = int(summary.get("total", meta.get("record_count", max(len(data) - 1, 0))))

          per_source = summary.get("per_source", {})
          per_topic = summary.get("per_topic", {})

          lines = []
          lines.append("## Imports → Appendix A summary")
          lines.append("")
          lines.append(f"- Channel: `{meta.get('channel', 'manual_import')}`")
          lines.append(f"- Provider: `{meta.get('provider', 'unknown')}`")
          lines.append(f"- Output file: `{summary_path.as_posix()}`")
          lines.append(f"- Total unique records: **{total}**")
          lines.append("")
          if per_source:
            lines.append("### Per source")
            lines.append("")
            lines.append("| Source | Records |")
            lines.append("|--------|---------|")
            for src, count in per_source.items():
              lines.append(f"| {src} | {count} |")
            lines.append("")
          if per_topic:
            lines.append("### Per topic")
            lines.append("")
            lines.append("| Topic ID | Records |")
            lines.append("|----------|---------|")
            for topic, count in per_topic.items():
              lines.append(f"| {topic} | {count} |")
            lines.append("")

          lines.append("## Imports → Appendix A")
          lines.append("")
          lines.append(f"- Provider: `{meta.get('provider', 'unknown')}`")
          lines.append(f"- CSV path: `{meta.get('source_csv_path', 'N/A')}`")
          lines.append(f"- Query topic: `{meta.get('query_topic', 'N/A')}`")
          yr = meta.get("year_range") or {}
          y0 = yr.get("from")
          y1 = yr.get("to")
          if y0 and y1:
            lines.append(f"- Year range (metadata): `{y0}–{y1}`")
          lines.append("")
          lines.append("The converter writes an Appendix A-style JSON file into `json_jsonl/`.")
          lines.append("You can now run Appendix B screening against that artefact after persisting it in the repository.")

          step_summary = os.environ.get("GITHUB_STEP_SUMMARY")
          if step_summary:
            with open(step_summary, "a", encoding="utf-8") as fh:
              fh.write("\n".join(lines) + "\n")
          PY

      # ------------------------------------------------------------------
      # Persist the output as a short-lived artifact so reviewers can
      # download and then update json_jsonl/ELIS_Appendix_A_Search_rows.json
      # via a PR without any local Python run.
      # ------------------------------------------------------------------
      - name: Upload Appendix A JSON artifact
        if: ${{ always() && hashFiles('json_jsonl/ELIS_Appendix_A_Search_rows.json') != '' }}
        uses: actions/upload-artifact@v4
        with:
          name: elis-imports-appendix-a
          path: json_jsonl/ELIS_Appendix_A_Search_rows.json
          retention-days: 14
